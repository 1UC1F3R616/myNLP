# -*- coding: utf-8 -*-
"""MovieReviewClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kUVEoAyaKV8Mm6RSnbun7S8M8RfKpduj

## Steps
- Importing Libraries
- Data Pre-Processing
- Split the dataset into Train and Test set
- Train the Classifier
- Test the Accuracy
"""

import nltk
import random # To shuffle the dataset
from nltk.corpus import movie_reviews # 1K negative, 1K positive Reviews

"""## Data Pre-Processing Steps
- Create the List of Tuples
- Shuffle the Documents
- Normalize the Dataset
- Convert word list into nltk frequency distribution
- Limit the words
- Find Features within the documents
"""

import nltk
  nltk.download('movie_reviews')

documents = []

for category in movie_reviews.categories():
  for fileid in movie_reviews.fileids(category):
    documents.append((list(movie_reviews.words(fileid)), category))

random.shuffle(documents)
print(documents[1])

# for x in movie_reviews.categories():
#   for y in movie_reviews.fileids(category):
#     print(y) # individual files

all_words = []
for word in movie_reviews.words():
  all_words.append(word.lower())

all_words = nltk.FreqDist(all_words)
print(all_words.most_common(15))
print(all_words['love'])

# limit the words
word_features = list(all_words.keys())[:3000]

def find_features(document):
  words = set(document)
  features = {}
  for w in word_features:
    features[w] = (w in words)
  return features

print(find_features(movie_reviews.words('neg/cv000_29416.txt')))

featuresets = [(find_features(rev), category) for (rev, category) in documents]

# Working for Model
training_set = featuresets[:1900]
testing_set = featuresets[1900:]

classifer = nltk.NaiveBayesClassifier.train(training_set)

## Testing the Accuracy
print('Accuracy {}'.format(nltk.classify.accuracy(classifer, testing_set)*100))

classifier.show_most_informative_features(15)